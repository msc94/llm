{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f853ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941b668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"data/german_words.txt\", \"r\").read().splitlines()\n",
    "print(f\"Original length: {len(words)}\")\n",
    "\n",
    "def contains_illegal_char(word):\n",
    "    allowed_chars = list(string.ascii_lowercase) + list(\" -äöüß\")\n",
    "    return any(c not in allowed_chars for c in word)\n",
    "\n",
    "# Clean up words a little and remove lots of characters that rarely occur\n",
    "words = [w.lower() for w in words]\n",
    "words = [w for w in words if not contains_illegal_char(w)]\n",
    "\n",
    "print(f\"New length: {len(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584fcd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(\"\".join(words))))\n",
    "\n",
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "stoi[\"<S>\"] = len(stoi)\n",
    "stoi[\"<E>\"] = len(stoi)\n",
    "\n",
    "num_chars = len(stoi)\n",
    "\n",
    "itos = {i:s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75992941",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((num_chars, num_chars), dtype=torch.long)\n",
    "for w in words:\n",
    "    chs = [\"<S>\"] + list(w) + [\"<E>\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1\n",
    "        \n",
    "P = N.float() / N.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff365f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 24))\n",
    "plt.imshow(N)\n",
    "\n",
    "for i in range(num_chars):\n",
    "    for j in range(num_chars):\n",
    "        bigram = itos[i] + itos[j]\n",
    "        plt.text(j, i, bigram, ha=\"center\", va=\"top\")\n",
    "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"bottom\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word():\n",
    "    result = []\n",
    "    \n",
    "    ix = stoi[\"<S>\"]\n",
    "    end = stoi[\"<E>\"]\n",
    "    \n",
    "    while True:\n",
    "        probs = P[ix, :]\n",
    "        \n",
    "        sample = torch.multinomial(probs, 1, replacement=True).item()\n",
    "        if sample == end:\n",
    "            break\n",
    "            \n",
    "        result.append(itos[sample])\n",
    "        ix = sample\n",
    "    \n",
    "    return \"\".join(result)\n",
    "    \n",
    "for i in range(100):\n",
    "    print(f\"{i}: {sample_word()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for w in words:\n",
    "    chs = [\"<S>\"] + list(w) + [\"<E>\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        \n",
    "        prob = P[ix1, ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        \n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "        \n",
    "nll = -log_likelihood / n\n",
    "print(f\"{nll=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd99d88",
   "metadata": {},
   "source": [
    "# NN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255da4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input dataset from bigrams\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = [\"<S>\"] + list(w) + [\"<E>\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        \n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "print(xs.shape)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c5d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "W = torch.randn((num_chars, num_chars), dtype=torch.float32, requires_grad=True)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f84899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration():\n",
    "    # --- Forward pass ---\n",
    "    \n",
    "    # Input to the NN (B, num_chars)\n",
    "    xenc = F.one_hot(xs, num_classes=num_chars).float()\n",
    "    \n",
    "    # Output of the NN (B, num_chars)\n",
    "    logits = torch.mm(xenc, W)\n",
    "    \n",
    "    # Make all outputs positive\n",
    "    # Also interpret as counts\n",
    "    counts = logits.exp()\n",
    "    \n",
    "    # And normalize to a distribution\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    \n",
    "    # Calculate loss function\n",
    "    batch_size, _ = probs.shape\n",
    "    loss = -probs[torch.arange(batch_size), ys].log().mean()\n",
    "    \n",
    "    print(f\"{loss=}\")\n",
    "    \n",
    "    # --- Backward pass ---\n",
    "    \n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    W.data -= 10 * W.grad\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "for i in range(10000):\n",
    "    loss = iteration()\n",
    "    if i % 1000:\n",
    "        print(f\"{loss=}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac02f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
